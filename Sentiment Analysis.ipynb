{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":2510329,"sourceType":"datasetVersion","datasetId":1520310}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom datasets import Dataset\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\nfrom sklearn.model_selection import train_test_split\nfrom transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\nfrom sklearn.metrics import accuracy_score, f1_score\nimport numpy as np\nfrom transformers import pipeline\nfrom collections import Counter\nimport nltk\nfrom nltk.corpus import stopwords\nfrom sklearn.preprocessing import LabelEncoder\nfrom transformers import pipeline\n\nimport os\nos.environ[\"WANDB_DISABLED\"] = \"true\" ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T16:10:28.035995Z","iopub.execute_input":"2025-08-09T16:10:28.036637Z","iopub.status.idle":"2025-08-09T16:10:55.524326Z","shell.execute_reply.started":"2025-08-09T16:10:28.036612Z","shell.execute_reply":"2025-08-09T16:10:55.523477Z"}},"outputs":[{"name":"stderr","text":"2025-08-09 16:10:42.639741: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1754755842.832336      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1754755842.892341      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/input/twitter-entity-sentiment-analysis/twitter_training.csv', header=None)\ndf_validation = pd.read_csv('/kaggle/input/twitter-entity-sentiment-analysis/twitter_validation.csv', header=None)\n\ndf_train.columns = ['ID', 'Entity', 'Sentiment', 'Text']\ndf_validation.columns = ['ID', 'Entity', 'Sentiment', 'Text']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T16:10:55.525385Z","iopub.execute_input":"2025-08-09T16:10:55.525906Z","iopub.status.idle":"2025-08-09T16:10:55.821383Z","shell.execute_reply.started":"2025-08-09T16:10:55.525887Z","shell.execute_reply":"2025-08-09T16:10:55.820570Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"df_train.dropna(subset=['Text'], inplace=True)\ndf_validation.dropna(subset=['Text'], inplace=True)\n\nlabels = df_train['Sentiment'].unique()\nlabel2id = {label: i for i, label in enumerate(labels)}\nid2label = {i: label for i, label in enumerate(labels)}\n\ndf_train['label'] = df_train['Sentiment'].map(label2id)\ndf_validation['label'] = df_validation['Sentiment'].map(label2id)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T16:10:55.863351Z","iopub.execute_input":"2025-08-09T16:10:55.863539Z","iopub.status.idle":"2025-08-09T16:10:55.872402Z","shell.execute_reply.started":"2025-08-09T16:10:55.863516Z","shell.execute_reply":"2025-08-09T16:10:55.871717Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"train_dataset = Dataset.from_pandas(df_train[['Text', 'label']].rename(columns={'Text': 'text'}))\nvalidation_dataset = Dataset.from_pandas(df_validation[['Text', 'label']].rename(columns={'Text': 'text'}))\n\nprint(\"Data cleaned and prepared.\")\nprint(f\"Number of labels: {len(labels)}\")\nprint(\"Label to ID mapping:\", label2id)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T16:10:55.890480Z","iopub.execute_input":"2025-08-09T16:10:55.890648Z","iopub.status.idle":"2025-08-09T16:10:55.994310Z","shell.execute_reply.started":"2025-08-09T16:10:55.890634Z","shell.execute_reply":"2025-08-09T16:10:55.993590Z"}},"outputs":[{"name":"stdout","text":"Data cleaned and prepared.\nNumber of labels: 4\nLabel to ID mapping: {'Positive': 0, 'Neutral': 1, 'Negative': 2, 'Irrelevant': 3}\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"model_name = \"bert-base-uncased\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\ndef tokenize_function(examples):\n    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=128)\n\ntokenized_train_dataset = train_dataset.map(tokenize_function, batched=True)\ntokenized_validation_dataset = validation_dataset.map(tokenize_function, batched=True)\n\nprint(\"Datasets tokenized successfully!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T16:10:55.995330Z","iopub.execute_input":"2025-08-09T16:10:55.995587Z","iopub.status.idle":"2025-08-09T16:11:06.270864Z","shell.execute_reply.started":"2025-08-09T16:10:55.995562Z","shell.execute_reply":"2025-08-09T16:11:06.270293Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"69d03b97d9e3456a9142abcff93c0dc1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ca42d1650daa42aca22e620ce2ac0159"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"584a37fc3a1047c68b6267b8727090c5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e6fa2c2a76da4918b86826ad6b86d0c8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/73996 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3fb9201c055a47f6ab0361497754a4cf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9887cb3d2df446a8619d65612a8c65c"}},"metadata":{}},{"name":"stdout","text":"Datasets tokenized successfully!\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"model = AutoModelForSequenceClassification.from_pretrained(\n    model_name,\n    num_labels=len(labels),\n    label2id=label2id,\n    id2label=id2label\n)\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    predictions = np.argmax(logits, axis=-1)\n    acc = accuracy_score(labels, predictions)\n    f1 = f1_score(labels, predictions, average=\"weighted\")\n    return {\"accuracy\": acc, \"f1\": f1}\n\ntraining_args = TrainingArguments(\n    output_dir=\"./results\",\n    num_train_epochs=4,\n    per_device_train_batch_size=32,\n    per_device_eval_batch_size=32,\n    warmup_steps=100,\n    weight_decay=0.01,\n    logging_dir=\"./logs\",\n    logging_steps=500,\n    report_to=\"none\"\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_train_dataset,\n    eval_dataset=tokenized_validation_dataset,\n    compute_metrics=compute_metrics,\n)\n\nprint(\" Starting model fine-tuning...\")\ntrainer.train()\n\nprint(\"Evaluating final model...\")\nfinal_metrics = trainer.evaluate()\nprint(final_metrics)\n\nprint(\" Model fine-tuning complete!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T16:16:24.196095Z","iopub.execute_input":"2025-08-09T16:16:24.196375Z","iopub.status.idle":"2025-08-09T17:19:24.362081Z","shell.execute_reply.started":"2025-08-09T16:16:24.196352Z","shell.execute_reply":"2025-08-09T17:19:24.361339Z"}},"outputs":[{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":" Starting model fine-tuning...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='4628' max='4628' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [4628/4628 1:02:52, Epoch 4/4]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>0.969800</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.633200</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>0.332100</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>0.231000</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>0.165300</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>0.112600</td>\n    </tr>\n    <tr>\n      <td>3500</td>\n      <td>0.100400</td>\n    </tr>\n    <tr>\n      <td>4000</td>\n      <td>0.068900</td>\n    </tr>\n    <tr>\n      <td>4500</td>\n      <td>0.065700</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Evaluating final model...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [16/16 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"{'eval_loss': 0.17015519738197327, 'eval_accuracy': 0.961, 'eval_f1': 0.9610505430132918, 'eval_runtime': 4.5361, 'eval_samples_per_second': 220.452, 'eval_steps_per_second': 3.527, 'epoch': 4.0}\n Model fine-tuning complete!\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"sentiment_pipeline = pipeline(\"sentiment-analysis\", model=trainer.model, tokenizer=tokenizer)\n\nnew_texts = [\n    \"Nvidia's new graphics card is amazing!\",\n    \"I'm so angry about the new update for that game, it's unplayable.\",\n    \"This product is just okay, not great but not bad either.\",\n    \"Why is this article about politics in my gaming feed?\"\n]\n\npredictions = sentiment_pipeline(new_texts)\n\nprint(\"\\n--- Predictions on New Sentences ---\")\nfor text, result in zip(new_texts, predictions):\n    print(f\"\\nText: '{text}'\")\n    print(f\"Sentiment: {result['label']} (Score: {result['score']:.4f})\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T17:20:01.057421Z","iopub.execute_input":"2025-08-09T17:20:01.057984Z","iopub.status.idle":"2025-08-09T17:20:01.182573Z","shell.execute_reply.started":"2025-08-09T17:20:01.057961Z","shell.execute_reply":"2025-08-09T17:20:01.182023Z"}},"outputs":[{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"},{"name":"stdout","text":"\n--- Predictions on New Sentences ---\n\nText: 'Nvidia's new graphics card is amazing!'\nSentiment: Positive (Score: 0.9991)\n\nText: 'I'm so angry about the new update for that game, it's unplayable.'\nSentiment: Negative (Score: 0.9999)\n\nText: 'This product is just okay, not great but not bad either.'\nSentiment: Irrelevant (Score: 0.9617)\n\nText: 'Why is this article about politics in my gaming feed?'\nSentiment: Negative (Score: 0.9974)\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"output_save_dir = \"twitter_sentiment_model_final\"\n\ntrainer.save_model(output_save_dir)\n\ntokenizer.save_pretrained(output_save_dir)\n\nprint(f\"Model and tokenizer have been saved to the '{output_save_dir}' directory.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T17:20:14.201473Z","iopub.execute_input":"2025-08-09T17:20:14.201723Z","iopub.status.idle":"2025-08-09T17:20:14.772669Z","shell.execute_reply.started":"2025-08-09T17:20:14.201706Z","shell.execute_reply":"2025-08-09T17:20:14.772046Z"}},"outputs":[{"name":"stdout","text":"Model and tokenizer have been saved to the 'twitter_sentiment_model_final' directory.\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}